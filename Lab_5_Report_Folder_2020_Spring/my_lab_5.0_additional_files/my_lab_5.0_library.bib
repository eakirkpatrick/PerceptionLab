
@article{cohen_things_1990,
	title = {Things I have learned (so far)},
	volume = {45},
	issn = {1935-990X(Electronic),0003-066X(Print)},
	doi = {10.1037/0003-066X.45.12.1304},
	abstract = {This is an account of what I have learned (so far) about the application of statistics to psychology and the other sociobiomedical sciences. It includes the principles "less is more" (fewer variables, more highly targeted issues, sharp rounding off), "simple is better" (graphic representation, unit weighting for linear composites), and "some things you learn aren't so." I have learned to avoid the many misconceptions that surround Fisherian null hypothesis testing. I have also learned the importance of power analysis and the determination of just how big (rather than how statistically significant) are the effects that we study. Finally, I have learned that there is no royal road to statistical induction, that the informed judgment of the investigator is the crucial element in the interpretation of data, and that things take time. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {1304--1312},
	number = {12},
	journaltitle = {American Psychologist},
	author = {Cohen, Jacob},
	date = {1990},
	keywords = {Effect size, Statistics, *Psychology, *Social Sciences}
}

@book{cohen_statistical_1988,
	location = {Hillsdale, {NJ}},
	edition = {2nd},
	title = {Statistical power analysis for the behavioral sciences},
	isbn = {0-8058-0283-5},
	pagetotal = {xxi, 567},
	publisher = {L. Erlbaum Associates},
	author = {Cohen, Jacob},
	date = {1988},
	keywords = {Probabilities., Social sciences Statistical methods.}
}


@article{peirce_psychopy2_2019,
	title = {{PsychoPy}2: Experiments in behavior made easy},
	issn = {1554-3528},
	doi = {10.3758/s13428-018-01193-y},
	abstract = {{PsychoPy} is an application for the creation of experiments in behavioral science (psychology, neuroscience, linguistics, etc.) with precise spatial control and timing of stimuli. It now provides a choice of interface; users can write scripts in Python if they choose, while those who prefer to construct experiments graphically can use the new Builder interface. Here we describe the features that have been added over the last 10 years of its development. The most notable addition has been that Builder interface, allowing users to create studies with minimal or no programming, while also allowing the insertion of Python code for maximal flexibility. We also present some of the other new features, including further stimulus options, asynchronous time-stamped hardware polling, and better support for open science and reproducibility. Tens of thousands of users now launch {PsychoPy} every month, and more than 90 people have contributed to the code. We discuss the current state of the project, as well as plans for the future.},
	journaltitle = {Behavior Research Methods},
	author = {Peirce, Jonathan W. and Gray, Jeremy R. and Simpson, Sol and {MacAskill}, Michael and Höchenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindeløv, Jonas Kristoffer},
	date = {2019-02-07},
	keywords = {Experimental Design}
}

@book{peirce_building_2018,
	location = {Thousand Oaks, {CA}},
	edition = {1st edition.},
	title = {Building Experiments in {PsychoPy}},
	isbn = {9781473991392 (pbk. alk. paper) 9781473991385 (hardback alk. paper)},
	pagetotal = {pages cm},
	publisher = {{SAGE} Publications},
	author = {Peirce, Jonathan W. and {MacAskill}, Michael},
	date = {2018},
	keywords = {Psychophysical Measurement}
}

@article{peirce_generating_2009,
	title = {Generating stimuli for neuroscience using {PsychoPy}},
	volume = {2},
	doi = {10.3389/neuro.11.010.2008},
	abstract = {{PsychoPy} is a software library written in Python, using {OpenGL} to generate very precise visual stimuli on standard personal computers. It is designed to allow the construction of as wide a variety of neuroscience experiments as possible, with the least effort. By writing scripts in standard Python syntax users can generate an enormous variety of visual and auditory stimuli and can interact with a wide range of external hardware (enabling its use in {fMRI}, {EEG}, {MEG} etc.). The structure of scripts is simple and intuitive. As a result, new experiments can be written very quickly, and trying to understand a previously written script is easy, even with minimal code comments. {PsychoPy} can also generate movies and image sequences to be used in demos or simulated neuroscience experiments. This paper describes the range of tools and stimuli that it provides and the environment in which experiments are conducted.},
	pages = {1--8},
	issue = {January},
	journaltitle = {Frontiers in Neuroinformatics},
	author = {Peirce, Jonathan W.},
	date = {2009-01-15},
	keywords = {Ambrose Soehn, Python, psychophysics, software, neuroscience, vision, {fMRI}, {EEG}, {MEG}}
}

@article{peirce_psychopy_psychophysics_2007,
	title = {{PsychoPy}--Psychophysics software in Python},
	volume = {162},
	issn = {0165-0270},
	doi = {10.1016/j.jneumeth.2006.11.017},
	pages = {8--13},
	number = {1},
	journaltitle = {Journal of Neuroscience Methods},
	author = {Peirce, Jonathan W.},
	date = {2007},
	keywords = {Vision, Psychophysics, Software, Ambrose Soehn, Psychometric, Stimulus presentation}
}

 @Manual{RStudio2019,
    title = {RStudio: Integrated Development Environment for R},
    author = {{RStudio Team}},
    organization = {RStudio, Inc.},
    address = {Boston, MA},
    year = {2019},
    url = {http://www.rstudio.com/},
  }

@article{SHINNCUNNINGHAM2008182,
title = "Object-based auditory and visual attention",
journal = "Trends in Cognitive Sciences",
volume = "12",
number = "5",
pages = "182 - 186",
year = "2008",
issn = "1364-6613",
doi = "https://doi.org/10.1016/j.tics.2008.02.003",
url = "http://www.sciencedirect.com/science/article/pii/S1364661308000600",
author = "Barbara G. Shinn-Cunningham",
abstract = "Theories of visual attention argue that attention operates on perceptual objects, and thus that interactions between object formation and selective attention determine how competing sources interfere with perception. In auditory perception, theories of attention are less mature and no comprehensive framework exists to explain how attention influences perceptual abilities. However, the same principles that govern visual perception can explain many seemingly disparate auditory phenomena. In particular, many recent studies of ‘informational masking’ can be explained by failures of either auditory object formation or auditory object selection. This similarity suggests that the same neural mechanisms control attention and influence perception across different sensory modalities."
}

@article{CHRISTENSEN20192041,
title = "White Noise Background Improves Tone Discrimination by Suppressing Cortical Tuning Curves",
journal = "Cell Reports",
volume = "29",
number = "7",
pages = "2041 - 2053.e4",
year = "2019",
issn = "2211-1247",
doi = "https://doi.org/10.1016/j.celrep.2019.10.049",
url = "http://www.sciencedirect.com/science/article/pii/S2211124719313634",
author = "Rasmus Kordt Christensen and Henrik Lindén and Mari Nakamura and Tania Rinaldi Barkat",
keywords = "auditory cortex, sensory-driven behavior, background noise, optogenetics, parvalbumin interneurons, awake electrophysiological recordings, decision making, sensory processing, population coding",
abstract = "Summary
The brain faces the difficult task of maintaining a stable representation of key features of the outside world in noisy sensory surroundings. How does the sensory representation change with noise, and how does the brain make sense of it? We investigated the effect of background white noise (WN) on tuning properties of neurons in mouse A1 and its impact on discrimination performance in a go/no-go task. We find that WN suppresses the activity of A1 neurons, which surprisingly increases the discriminability of tones spectrally close to each other. To confirm the involvement of A1, we optogenetically excited parvalbumin-positive (PV+) neurons in A1, which have similar effects as WN on both tuning properties and frequency discrimination. A population model suggests that the suppression of A1 tuning curves increases frequency selectivity and thereby improves discrimination. Our findings demonstrate that the cortical representation of pure tones adapts during noise to improve sensory acuity."
}

@article{LAKATOS2009419,
title = "The Leading Sense: Supramodal Control of Neurophysiological Context by Attention",
journal = "Neuron",
volume = "64",
number = "3",
pages = "419 - 430",
year = "2009",
issn = "0896-6273",
doi = "https://doi.org/10.1016/j.neuron.2009.10.014",
url = "http://www.sciencedirect.com/science/article/pii/S089662730900840X",
author = "Peter Lakatos and Monica N. O'Connell and Annamaria Barczak and Aimee Mills and Daniel C. Javitt and Charles E. Schroeder",
keywords = "SYSNEURO",
abstract = "Summary
Attending to a stimulus enhances its neuronal representation, even at the level of primary sensory cortex. Cross-modal modulation can similarly enhance a neuronal representation, and this process can also operate at the primary cortical level. Phase reset of ongoing neuronal oscillatory activity has been shown to be an important element of the underlying modulation of local cortical excitability in both cases. We investigated the influence of attention on oscillatory phase reset in primary auditory and visual cortices of macaques performing an intermodal selective attention task. In addition to responses “driven” by preferred modality stimuli, we noted that both preferred and nonpreferred modality stimuli could “modulate” local cortical excitability by phase reset of ongoing oscillatory activity, and that this effect was linked to their being attended. These findings outline a supramodal mechanism by which attention can control neurophysiological context, thus determining the representation of specific sensory content in primary sensory cortex."
}

@article {GAU2020,
article_type = {journal},
title = {Resolving multisensory and attentional influences across cortical depth in sensory cortices},
author = {Gau, Remi and Bazin, Pierre-Louis and Trampel, Robert and Turner, Robert and Noppeney, Uta},
editor = {de Lange, Floris P and Büchel, Christian and de Lange, Floris P and Huber, Laurentius and Norris, David G},
volume = 9,
year = 2020,
month = {jan},
pub_date = {2020-01-08},
pages = {e46856},
citation = {eLife 2020;9:e46856},
doi = {10.7554/eLife.46856},
url = {https://doi.org/10.7554/eLife.46856},
abstract = {In our environment, our senses are bombarded with a myriad of signals, only a subset of which is relevant for our goals. Using sub-millimeter-resolution fMRI at 7T, we resolved BOLD-response and activation patterns across cortical depth in early sensory cortices to auditory, visual and audiovisual stimuli under auditory or visual attention. In visual cortices, auditory stimulation induced widespread inhibition irrespective of attention, whereas auditory relative to visual attention suppressed mainly central visual field representations. In auditory cortices, visual stimulation suppressed activations, but amplified responses to concurrent auditory stimuli, in a patchy topography. Critically, multisensory interactions in auditory cortices were stronger in deeper laminae, while attentional influences were greatest at the surface. These distinct depth-dependent profiles suggest that multisensory and attentional mechanisms regulate sensory processing via partly distinct circuitries. Our findings are crucial for understanding how the brain regulates information flow across senses to interact with our complex multisensory world.},
keywords = {multisensory integration, audiovisual, primary sensory cortices, deactivations,, crossmodal attention, cortical layers},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}

@article{SAWAMURA2014,
author = {Daisuke Sawamura and Katsunori Ikoma and Kazuki Yoshida and Yuji Inagaki and Keita Ogawa and Shinya Sakai},
title = {Active inhibition of task-irrelevant sounds and its neural basis in patients with attention deficits after traumatic brain injury},
journal = {Brain Injury},
volume = {28},
number = {11},
pages = {1455-1460},
year  = {2014},
publisher = {Taylor & Francis},
doi = {10.3109/02699052.2014.919531},

URL = { 
        https://doi.org/10.3109/02699052.2014.919531
    
},
eprint = { 
        https://doi.org/10.3109/02699052.2014.919531
    
}

}


@INPROCEEDINGS{6469716,
author={Z. {Zhao} and L. {Xie}},
booktitle={2012 5th International Congress on Image and Signal Processing},
title={The influence of visual stimuli on just noticeable difference of loudness},
year={2012},
volume={},
number={},
pages={1673-1676},
keywords={acoustic signal processing;audio signal processing;eye;image colour analysis;image motion analysis;medical image processing;visual perception;auditory-visual interaction;loudness JND;audio stimuli;illumination;moving state;image quality;color feature;image feature;psychoacoustic experiment;pure-tone loudness;just noticeable difference;visual stimuli;Visualization;Lighting;Image color analysis;Colored noise;Color;Standards;loudness;JND;auditory-visual interaction},
doi={10.1109/CISP.2012.6469716},
ISSN={null},
month={Oct},}

@article{DUNCAN1980,
author={Duncan,John},
year={1980},
month={05},
title={The locus of interference in the perception of simultaneous stimuli},
journal={Psychological review},
volume={87},
number={3},
pages={272-300},
note={Copyright - © 1980, American Psychological Association; Date revised - 19800101; 20060329; Number of references - 74; Last updated - 2017-10-02; SubjectsTermNotLitGenreText - Auditory Discrimination 2518P9A 6514P9A 6520P9A 782P9A 791P9A 9028P9A 2431PS5 6264PS5 6270PS5 755PS5 764PS5 8698PS5; Divided Attention 1708P9A 1945P9A 2581P9A 747P9A 863P9A 9028P9A 1885PS5 2489PS5 720PS5 832PS5 8698PS5; Human Channel Capacity 1708P9A 4156P9A 9028P9A 4000PS5; Visual Discrimination 2518P9A 6514P9A 6520P9A 9028P9A 9452P9A 9464P9A 2431PS5 6264PS5 6270PS5 8698PS5 9099PS5 9110PS5 9121PS5; Visual Displays 2545P9A 6535P9A 8581P9A 9028P9A 9453P9A 9470P9A 2455PS5 6284PS5 8270PS5 8698PS5 9111PS5 9127PS5; 2956P9A 3210P9A 3219P9A 5411P9A 8602P9A 9028P9A 2845PS5 3094PS5 5211PS5 8291PS5 8698PS5},
abstract={In 3 experiments with 48 college students (18–33 yrs old), performance on well-practiced target detection tasks, both auditory and visual, was little influenced by the number of simultaneous nontargets, but suffered if simultaneous targets were detected separately. It is suggested that only targets need pass through a limited-capacity system leading to awareness (and hence availability for report); nontargets can be identified and rejected by earlier parallel, unconscious processes. Since nontarget words can be rejected on the basis of meaning, stimuli must be fully identified before the limited-capacity system. More generally, performance decrements due to divided attention are usually marked whenever simultaneous stimuli (psychophysical, verbal) must be identified separately and independently; under these circumstances all stimuli must pass through the limited-capacity system to awareness. (74 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
keywords={separate detection of & number of simultaneous nontarget stimuli, attentional interference in auditory & visual target detection task performance, 18–33 yr olds; Psychology; Human; Visual Displays; Divided Attention; Visual Discrimination; Stimulus Presentation Methods; Auditory Discrimination; Human Channel Capacity; article; 2300:Human Experimental Psychology; Humans; Attention; Visual Perception; Auditory Perception; Discrimination Learning},
isbn={0033-295X, 0033-295X},
language={English},
url={https://colorado.idm.oclc.org/login?url=https://search-proquest-com.colorado.idm.oclc.org/docview/614361766?accountid=14503},
}