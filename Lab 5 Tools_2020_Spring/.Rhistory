filelist <- list.files(path = path_name, pattern = "\\.csv")
# calculate the number of subjects
n.subjects <- length(filelist)
# create vector of 1:n subject numbers in random order
if(randomize) {
subject.no <- sample(1:n.subjects)
} else {
subject.no <- 1:n.subjects
}
# create a vector of subject identifiers
# to be used in place of initials
subjID <- paste("s", formatC(subject.no, width = 2, format = "d", flag = "0"), sep = "")
msg <- paste("Number of files to be aggregated =", n.subjects)
print(msg)
# loop through all the data files and create
# one data frame from all of them
# you can elimate some of the columns if you know which ones you want to keep
# change the names as appropriate in 'keep' below to save those columns and
# then uncomment the "keep" line below.
# keep <- c("participant", "trials.thisN", "resp.keys", "resp.rt", "date", "expName")
df.all <- data.frame()
file.count <- 0
for (fn in filelist) {
file.count <- file.count + 1
print(paste("processing file no.", file.count, "  ", fn,
"   subject number", subject.no[file.count]))
# read file
tmp <- read.csv(file.path(path_name, fn)) %>%
# remove the 2 rows with no words
filter(Word != "") %>%
# put subjID into the participant column
mutate(participant = subjID[file.count]) %>%
# remove levels that are empty
droplevels()
# keep desire columns
# if (exists('keep')) tmp <- tmp[, keep]
# add this subject to data frame all
df.all <- rbind(df.all, tmp)
}
names(tmp)
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
rm(list = ls())
# name of output file (change the name if you want to)
file.output <- "my_experiment_aggregated_data.csv"
# turn off randomizing order of subjects
# helps locate problem files.
# Set to TRUE when all the problems are solved
randomize <- TRUE
# find folder with the data files
path_name <- dirname(file.choose())
# make a list of just the csv files
filelist <- list.files(path = path_name, pattern = "\\.csv")
# calculate the number of subjects
n.subjects <- length(filelist)
# create vector of 1:n subject numbers in random order
if(randomize) {
subject.no <- sample(1:n.subjects)
} else {
subject.no <- 1:n.subjects
}
# create a vector of subject identifiers
# to be used in place of initials
subjID <- paste("s", formatC(subject.no, width = 2, format = "d", flag = "0"), sep = "")
msg <- paste("Number of files to be aggregated =", n.subjects)
print(msg)
# loop through all the data files and create
# one data frame from all of them
# you can elimate some of the columns if you know which ones you want to keep
# change the names as appropriate in 'keep' below to save those columns and
# then uncomment the "keep" line below.
# keep <- c("participant", "trials.thisN", "resp.keys", "resp.rt", "date", "expName")
df.all <- data.frame()
file.count <- 0
for (fn in filelist) {
file.count <- file.count + 1
print(paste("processing file no.", file.count, "  ", fn,
"   subject number", subject.no[file.count]))
# read file
tmp <- read.csv(file.path(path_name, fn)) %>%
# remove the 2 rows with no words
filter(Word != "") %>%
# put subjID into the participant column
mutate(participant = subjID[file.count]) %>%
# remove levels that are empty
droplevels() %>%
# get rid of X column if present
select(-X)
# keep desire columns
# if (exists('keep')) tmp <- tmp[, keep]
# add this subject to data frame all
df.all <- rbind(df.all, tmp)
}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
rm(list = ls())
# name of output file (change the name if you want to)
file.output <- "my_experiment_aggregated_data.csv"
# turn off randomizing order of subjects
# helps locate problem files.
# Set to TRUE when all the problems are solved
randomize <- TRUE
# find folder with the data files
path_name <- dirname(file.choose())
# make a list of just the csv files
filelist <- list.files(path = path_name, pattern = "\\.csv")
# calculate the number of subjects
n.subjects <- length(filelist)
# create vector of 1:n subject numbers in random order
if(randomize) {
subject.no <- sample(1:n.subjects)
} else {
subject.no <- 1:n.subjects
}
# create a vector of subject identifiers
# to be used in place of initials
subjID <- paste("s", formatC(subject.no, width = 2, format = "d", flag = "0"), sep = "")
msg <- paste("Number of files to be aggregated =", n.subjects)
print(msg)
# loop through all the data files and create
# one data frame from all of them
# you can elimate some of the columns if you know which ones you want to keep
# change the names as appropriate in 'keep' below to save those columns and
# then uncomment the "keep" line below.
# keep <- c("participant", "trials.thisN", "resp.keys", "resp.rt", "date", "expName")
df.all <- data.frame()
file.count <- 0
for (fn in filelist) {
file.count <- file.count + 1
print(paste("processing file no.", file.count, "  ", fn,
"   subject number", subject.no[file.count]))
# read file
tmp <- read.csv(file.path(path_name, fn)) %>%
# remove the 2 rows with no words
filter(Word != "") %>%
# put subjID into the participant column
mutate(participant = subjID[file.count]) %>%
# remove levels that are empty
droplevels() %>%
# get rid of X column if present
select(-"X")
# keep desire columns
# if (exists('keep')) tmp <- tmp[, keep]
# add this subject to data frame all
df.all <- rbind(df.all, tmp)
}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
rm(list = ls())
# name of output file (change the name if you want to)
file.output <- "my_experiment_aggregated_data.csv"
# turn off randomizing order of subjects
# helps locate problem files.
# Set to TRUE when all the problems are solved
randomize <- TRUE
# find folder with the data files
path_name <- dirname(file.choose())
# make a list of just the csv files
filelist <- list.files(path = path_name, pattern = "\\.csv")
# calculate the number of subjects
n.subjects <- length(filelist)
# create vector of 1:n subject numbers in random order
if(randomize) {
subject.no <- sample(1:n.subjects)
} else {
subject.no <- 1:n.subjects
}
# create a vector of subject identifiers
# to be used in place of initials
subjID <- paste("s", formatC(subject.no, width = 2, format = "d", flag = "0"), sep = "")
msg <- paste("Number of files to be aggregated =", n.subjects)
print(msg)
# loop through all the data files and create
# one data frame from all of them
# you can elimate some of the columns if you know which ones you want to keep
# change the names as appropriate in 'keep' below to save those columns and
# then uncomment the "keep" line below.
# keep <- c("participant", "trials.thisN", "resp.keys", "resp.rt", "date", "expName")
df.all <- data.frame()
file.count <- 0
for (fn in filelist) {
file.count <- file.count + 1
print(paste("processing file no.", file.count, "  ", fn,
"   subject number", subject.no[file.count]))
# read file
tmp <- read.csv(file.path(path_name, fn)) %>%
# remove the 2 rows with no words
filter(Word != "") %>%
# put subjID into the participant column
mutate(participant = subjID[file.count]) %>%
# remove levels that are empty
droplevels() %>%
# get rid of X column if present
select(-matches("X"))
# keep desire columns
# if (exists('keep')) tmp <- tmp[, keep]
# add this subject to data frame all
df.all <- rbind(df.all, tmp)
}
# make participant a factor
df.all$participant <- factor(df.all$participant)
# reorder the subjects by ID value, placing them in random order
# to make them even more anonymous
df.all <- df.all[order(df.all$participant), ]
write.csv(df.all, file.output, row.names = FALSE)
print(paste("aggregated data written to file '", file.output, "'", sep = ""))
View(df.all)
summary(df.all)
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
rm(list = ls())
# name of output file (change the name if you want to)
file.output <- "my_experiment_aggregated_data.csv"
# turn off randomizing order of subjects
# helps locate problem files.
# Set to TRUE when all the problems are solved
randomize <- TRUE
# find folder with the data files
path_name <- dirname(file.choose())
# make a list of just the csv files
filelist <- list.files(path = path_name, pattern = "\\.csv")
# calculate the number of subjects
n.subjects <- length(filelist)
# create vector of 1:n subject numbers in random order
if(randomize) {
subject.no <- sample(1:n.subjects)
} else {
subject.no <- 1:n.subjects
}
# create a vector of subject identifiers
# to be used in place of initials
subjID <- paste("s", formatC(subject.no, width = 2, format = "d", flag = "0"), sep = "")
msg <- paste("Number of files to be aggregated =", n.subjects)
print(msg)
# loop through all the data files and create
# one data frame from all of them
# you can elimate some of the columns if you know which ones you want to keep
# change the names as appropriate in 'keep' below to save those columns and
# then uncomment the "keep" line below.
keep <- c("participant", "Work", "Valence", "Arousal", "Emotion",
"Word_Frequency", "Correct_Answer", "Correct_Response",
"key_resp_4.keys", "key_resp_4.corr", "key_resp_4.rt",
"date", "expName", "psychopyVersion", "frameRate")
df.all <- data.frame()
file.count <- 0
for (fn in filelist) {
file.count <- file.count + 1
print(paste("processing file no.", file.count, "  ", fn,
"   subject number", subject.no[file.count]))
# read file
tmp <- read.csv(file.path(path_name, fn)) %>%
# remove the 2 rows with no words
filter(Word != "") %>%
# put subjID into the participant column
mutate(participant = subjID[file.count]) %>%
# remove levels that are empty
droplevels() %>%
# get rid of X column if present
select(-matches("X")) %>%
# keep desired columns
select(keep)
# keep desire columns
# if (exists('keep')) tmp <- tmp[, keep]
# add this subject to data frame all
df.all <- rbind(df.all, tmp)
}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
rm(list = ls())
# name of output file (change the name if you want to)
file.output <- "my_experiment_aggregated_data.csv"
# turn off randomizing order of subjects
# helps locate problem files.
# Set to TRUE when all the problems are solved
randomize <- TRUE
# find folder with the data files
path_name <- dirname(file.choose())
# make a list of just the csv files
filelist <- list.files(path = path_name, pattern = "\\.csv")
# calculate the number of subjects
n.subjects <- length(filelist)
# create vector of 1:n subject numbers in random order
if(randomize) {
subject.no <- sample(1:n.subjects)
} else {
subject.no <- 1:n.subjects
}
# create a vector of subject identifiers
# to be used in place of initials
subjID <- paste("s", formatC(subject.no, width = 2, format = "d", flag = "0"), sep = "")
msg <- paste("Number of files to be aggregated =", n.subjects)
print(msg)
# loop through all the data files and create
# one data frame from all of them
# you can elimate some of the columns if you know which ones you want to keep
# change the names as appropriate in 'keep' below to save those columns and
# then uncomment the "keep" line below.
keep <- c("participant", "Word", "Valence", "Arousal", "Emotion",
"Word_Frequency", "Correct_Answer", "Correct_Response",
"key_resp_4.keys", "key_resp_4.corr", "key_resp_4.rt",
"date", "expName", "psychopyVersion", "frameRate")
df.all <- data.frame()
file.count <- 0
for (fn in filelist) {
file.count <- file.count + 1
print(paste("processing file no.", file.count, "  ", fn,
"   subject number", subject.no[file.count]))
# read file
tmp <- read.csv(file.path(path_name, fn)) %>%
# remove the 2 rows with no words
filter(Word != "") %>%
# put subjID into the participant column
mutate(participant = subjID[file.count]) %>%
# remove levels that are empty
droplevels() %>%
# get rid of X column if present
select(-matches("X")) %>%
# keep desired columns
select(keep)
# keep desire columns
# if (exists('keep')) tmp <- tmp[, keep]
# add this subject to data frame all
df.all <- rbind(df.all, tmp)
}
names(tmp)
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
rm(list = ls())
# name of output file (change the name if you want to)
file.output <- "my_experiment_aggregated_data.csv"
# turn off randomizing order of subjects
# helps locate problem files.
# Set to TRUE when all the problems are solved
randomize <- TRUE
# find folder with the data files
path_name <- dirname(file.choose())
# make a list of just the csv files
filelist <- list.files(path = path_name, pattern = "\\.csv")
# calculate the number of subjects
n.subjects <- length(filelist)
# create vector of 1:n subject numbers in random order
if(randomize) {
subject.no <- sample(1:n.subjects)
} else {
subject.no <- 1:n.subjects
}
# create a vector of subject identifiers
# to be used in place of initials
subjID <- paste("s", formatC(subject.no, width = 2, format = "d", flag = "0"), sep = "")
msg <- paste("Number of files to be aggregated =", n.subjects)
print(msg)
# loop through all the data files and create
# one data frame from all of them
# you can elimate some of the columns if you know which ones you want to keep
# change the names as appropriate in 'keep' below to save those columns and
# then uncomment the "keep" line below.
keep <- c("participant", "Word", "Valence", "Arousal", "Emotion",
"Word_Frequency", "Correct_Answer", "Correct_Response",
"key_resp_4.keys", "key_resp_4.corr", "key_resp_4.rt",
"date", "expName", "psychopyVersion", "frameRate")
df.all <- data.frame()
file.count <- 0
for (fn in filelist) {
file.count <- file.count + 1
print(paste("processing file no.", file.count, "  ", fn,
"   subject number", subject.no[file.count]))
# read file
tmp <- read.csv(file.path(path_name, fn)) %>%
# remove the 2 rows with no words
filter(Word != "") %>%
# put subjID into the participant column
mutate(participant = subjID[file.count]) %>%
# remove levels that are empty
droplevels() %>%
# get rid of X column if present
select(-matches("X"))
# keep desire columns
if (exists('keep')) tmp <- tmp[, keep]
# add this subject to data frame all
df.all <- rbind(df.all, tmp)
}
names(tmp)
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
rm(list = ls())
# name of output file (change the name if you want to)
file.output <- "my_experiment_aggregated_data.csv"
# turn off randomizing order of subjects
# helps locate problem files.
# Set to TRUE when all the problems are solved
randomize <- TRUE
# find folder with the data files
path_name <- dirname(file.choose())
# make a list of just the csv files
filelist <- list.files(path = path_name, pattern = "\\.csv")
# calculate the number of subjects
n.subjects <- length(filelist)
# create vector of 1:n subject numbers in random order
if(randomize) {
subject.no <- sample(1:n.subjects)
} else {
subject.no <- 1:n.subjects
}
# create a vector of subject identifiers
# to be used in place of initials
subjID <- paste("s", formatC(subject.no, width = 2, format = "d", flag = "0"), sep = "")
msg <- paste("Number of files to be aggregated =", n.subjects)
print(msg)
# loop through all the data files and create
# one data frame from all of them
# you can elimate some of the columns if you know which ones you want to keep
# change the names as appropriate in 'keep' below to save those columns and
# then uncomment the "keep" line below.
keep <- c("participant", "Word", "Valence", "Arousal", "Emotion",
"Word_Frequency", "Correct_Answer", "Correct_Response",
"key_resp_4.keys", "key_resp_4.corr", "key_resp_4.rt",
"date", "psychopyVersion", "frameRate")
df.all <- data.frame()
file.count <- 0
for (fn in filelist) {
file.count <- file.count + 1
print(paste("processing file no.", file.count, "  ", fn,
"   subject number", subject.no[file.count]))
# read file
tmp <- read.csv(file.path(path_name, fn)) %>%
# remove the 2 rows with no words
filter(Word != "") %>%
# put subjID into the participant column
mutate(participant = subjID[file.count]) %>%
# remove levels that are empty
droplevels() %>%
# get rid of X column if present
select(-matches("X"))
# keep desire columns
if (exists('keep')) tmp <- tmp[, keep]
# add this subject to data frame all
df.all <- rbind(df.all, tmp)
}
# make participant a factor
df.all$participant <- factor(df.all$participant)
# reorder the subjects by ID value, placing them in random order
# to make them even more anonymous
df.all <- df.all[order(df.all$participant), ]
write.csv(df.all, file.output, row.names = FALSE)
print(paste("aggregated data written to file '", file.output, "'", sep = ""))
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
rm(list = ls())
# name of output file (change the name if you want to)
file.output <- "group_06_aggregated_data.csv"
# turn off randomizing order of subjects
# helps locate problem files.
# Set to TRUE when all the problems are solved
randomize <- TRUE
# find folder with the data files
path_name <- dirname(file.choose())
# make a list of just the csv files
filelist <- list.files(path = path_name, pattern = "\\.csv")
# calculate the number of subjects
n.subjects <- length(filelist)
# create vector of 1:n subject numbers in random order
if(randomize) {
subject.no <- sample(1:n.subjects)
} else {
subject.no <- 1:n.subjects
}
# create a vector of subject identifiers
# to be used in place of initials
subjID <- paste("s", formatC(subject.no, width = 2, format = "d", flag = "0"), sep = "")
msg <- paste("Number of files to be aggregated =", n.subjects)
print(msg)
# loop through all the data files and create
# one data frame from all of them
# you can elimate some of the columns if you know which ones you want to keep
# change the names as appropriate in 'keep' below to save those columns and
# then uncomment the "keep" line below.
keep <- c("participant", "Word", "Valence", "Arousal", "Emotion",
"Word_Frequency", "Correct_Answer", "Correct_Response",
"key_resp_4.keys", "key_resp_4.corr", "key_resp_4.rt",
"date", "psychopyVersion", "frameRate")
df.all <- data.frame()
file.count <- 0
for (fn in filelist) {
file.count <- file.count + 1
print(paste("processing file no.", file.count, "  ", fn,
"   subject number", subject.no[file.count]))
# read file
tmp <- read.csv(file.path(path_name, fn)) %>%
# remove the 2 rows with no words
filter(Word != "") %>%
# put subjID into the participant column
mutate(participant = subjID[file.count]) %>%
# remove levels that are empty
droplevels() %>%
# get rid of X column if present
select(-matches("X"))
# keep desire columns
if (exists('keep')) tmp <- tmp[, keep]
# add this subject to data frame all
df.all <- rbind(df.all, tmp)
}
# make participant a factor
df.all$participant <- factor(df.all$participant)
# reorder the subjects by ID value, placing them in random order
# to make them even more anonymous
df.all <- df.all[order(df.all$participant), ]
write.csv(df.all, file.output, row.names = FALSE)
print(paste("aggregated data written to file '", file.output, "'", sep = ""))
install.packages(c("prodlim", "quadprog", "scales", "selectr", "tidyverse"))
library(stringr)
?str_pad
install.packages(c("gplots", "manipulateWidget", "mvtnorm"))
